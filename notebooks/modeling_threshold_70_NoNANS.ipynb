{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c3112f-6e26-42b7-9e00-9ce2131dc42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from matplotlib.colors import Colormap\n",
    "import scipy.stats as stats\n",
    "from numpy import interp\n",
    "import scikitplot as skplt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer, IterativeImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV, \n",
    "    cross_val_score, \n",
    "    cross_val_predict\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    r2_score,\n",
    "    mean_squared_error, \n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error, \n",
    "    mean_absolute_percentage_error,\n",
    "    accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    brier_score_loss,\n",
    "    f1_score,\n",
    "    roc_curve, \n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2728bffd-8a2d-40a3-b4bc-9394221ca02c",
   "metadata": {},
   "source": [
    "### Import DataFrame from Prepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21e0cd9-9a00-4afd-8174-40afb3d2b739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (176897, 44)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_threshed70.csv', low_memory=False)\n",
    "df = df.dropna()\n",
    "print(F\"Dataframe shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad9636-3944-43f5-a065-1564b28c8d87",
   "metadata": {},
   "source": [
    "### Converting Column Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0986d-395e-4c6c-ab80-565425b302b0",
   "metadata": {},
   "source": [
    "#### Object Columns to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab92989-4c10-4345-9b81-7c653a57dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns_to_change_to_category = [        \n",
    "    'eventDescription',  \n",
    "    'ecuSoftwareVersion',          \n",
    "    'ecuSerialNumber',         \n",
    "    'ecuModel',           \n",
    "    'ecuMake',                  \n",
    "    'EquipmentID',                                 \n",
    "    'LampStatus',\n",
    "    'next_derate_timestamp',\n",
    "    'time_until_derate'] \n",
    "\n",
    "for column in object_columns_to_change_to_category:\n",
    "    df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bbeab-07eb-42d3-b0bf-7c582cefc552",
   "metadata": {},
   "source": [
    "#### INT Columns to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbfc84b9-1a98-491d-a9a4-6bf80b0453e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_columns_to_categorical = ['RecordID',\n",
    "'ESS_Id',                    \n",
    "'ecuSource',                    \n",
    "'spn',                       \n",
    "'fmi',  \n",
    "'active',       \n",
    "'MCTNumber',                  \n",
    "'FaultId']\n",
    "for column in int_columns_to_categorical:\n",
    "    df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436ad387-a89f-4c1a-8773-739c716d826f",
   "metadata": {},
   "source": [
    "#### Date Columns to DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b153fc-d380-4b13-bed1-0e9ae1aa5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EventTimeStamp'] = pd.to_datetime(df['EventTimeStamp'])\n",
    "df['LocationTimeStamp'] = pd.to_datetime(df['LocationTimeStamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed3c6b-f3eb-40a6-9327-8293a6e025c0",
   "metadata": {},
   "source": [
    "### Splitting Data Train/Test before and After 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eae9061-316d-4ac7-bd55-99a990479acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date = '2019-01-01'\n",
    "df_train = df.sort_values('EventTimeStamp').loc[df['EventTimeStamp'] < test_date]\n",
    "df_test = df.sort_values('EventTimeStamp').loc[df['EventTimeStamp'] > test_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cb9ff27-f193-4e5d-a873-d2c5669394a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['target',\n",
    "            'LocationTimeStamp',\n",
    "            'EventTimeStamp',\n",
    "            'eventDescription',\n",
    "            'ESS_Id',\n",
    "            'ecuModel',\n",
    "            'ecuMake',\n",
    "            'ecuSource',\n",
    "            'ecuSoftwareVersion',\n",
    "            'ecuSerialNumber',\n",
    "            'MCTNumber',\n",
    "            'Latitude',\n",
    "            'Longitude',\n",
    "            'RecordID',\n",
    "            'next_derate_timestamp',\n",
    "            'time_until_derate',\n",
    "            'FaultId',\n",
    "            'EngineLoad',\n",
    "            'TurboBoostPressure',\n",
    "            'CruiseControlSetSpeed',\n",
    "            'DistanceLtd',\n",
    "             'LampStatus',\n",
    "            'Unnamed: 0'], axis=1)\n",
    "\n",
    "y_train = df_train['target'].values\n",
    "\n",
    "X_test = df_test.drop(['target',\n",
    "            'LocationTimeStamp',\n",
    "            'EventTimeStamp',\n",
    "            'eventDescription',\n",
    "            'ESS_Id',\n",
    "            'ecuModel',\n",
    "            'ecuMake',\n",
    "            'ecuSource',\n",
    "            'ecuSoftwareVersion',\n",
    "            'ecuSerialNumber',\n",
    "            'MCTNumber',\n",
    "            'Latitude',\n",
    "            'Longitude',\n",
    "            'RecordID',\n",
    "            'next_derate_timestamp',\n",
    "            'time_until_derate',\n",
    "            'FaultId',\n",
    "            'EngineLoad',\n",
    "            'TurboBoostPressure',\n",
    "            'CruiseControlSetSpeed',\n",
    "            'DistanceLtd',\n",
    "             'LampStatus',\n",
    "             'Unnamed: 0'], axis=1)\n",
    "\n",
    "y_test = df_test['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11e82331-05f2-4d57-81b4-4377b6f110eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 155901 entries, 17 to 945556\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count   Dtype   \n",
      "---  ------                     --------------   -----   \n",
      " 0   spn                        155901 non-null  category\n",
      " 1   fmi                        155901 non-null  category\n",
      " 2   active                     155901 non-null  category\n",
      " 3   activeTransitionCount      155901 non-null  int64   \n",
      " 4   EquipmentID                155901 non-null  category\n",
      " 5   AcceleratorPedal           155901 non-null  float64 \n",
      " 6   BarometricPressure         155901 non-null  float64 \n",
      " 7   CruiseControlActive        155901 non-null  bool    \n",
      " 8   EngineCoolantTemperature   155901 non-null  float64 \n",
      " 9   EngineOilPressure          155901 non-null  float64 \n",
      " 10  EngineOilTemperature       155901 non-null  float64 \n",
      " 11  EngineRpm                  155901 non-null  float64 \n",
      " 12  EngineTimeLtd              155901 non-null  float64 \n",
      " 13  FuelLevel                  155901 non-null  float64 \n",
      " 14  FuelLtd                    155901 non-null  float64 \n",
      " 15  FuelRate                   155901 non-null  float64 \n",
      " 16  IgnStatus                  155901 non-null  bool    \n",
      " 17  IntakeManifoldTemperature  155901 non-null  float64 \n",
      " 18  ParkingBrake               155901 non-null  bool    \n",
      " 19  Speed                      155901 non-null  float64 \n",
      " 20  Throttle                   155901 non-null  float64 \n",
      "dtypes: bool(3), category(4), float64(13), int64(1)\n",
      "memory usage: 19.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c55a1-e650-45b7-8fc3-776385e6af7e",
   "metadata": {},
   "source": [
    "### Evaluating What Rows were Dropped in Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a745146e-c2de-407d-88ca-1ab62b9c5faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of rows in the df (176897, 44) The amount of rows in Training Df (155901, 21) The amount of rows in Testing Df (20996, 21)\n"
     ]
    }
   ],
   "source": [
    "print(F\"The amount of rows in the df {df.shape} The amount of rows in Training Df {X_train.shape} The amount of rows in Testing Df {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1340001-0490-44e9-8740-a80b40bdf9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spn                          0\n",
       "fmi                          0\n",
       "active                       0\n",
       "activeTransitionCount        0\n",
       "EquipmentID                  0\n",
       "AcceleratorPedal             0\n",
       "BarometricPressure           0\n",
       "CruiseControlActive          0\n",
       "EngineCoolantTemperature     0\n",
       "EngineOilPressure            0\n",
       "EngineOilTemperature         0\n",
       "EngineRpm                    0\n",
       "EngineTimeLtd                0\n",
       "FuelLevel                    0\n",
       "FuelLtd                      0\n",
       "FuelRate                     0\n",
       "IgnStatus                    0\n",
       "IntakeManifoldTemperature    0\n",
       "ParkingBrake                 0\n",
       "Speed                        0\n",
       "Throttle                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "027374d9-3085-4269-84f9-2a21dcffd87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped_rows = df.merge(X_train, how=\"left\", indicator=True).query('_merge == \"left_only\"').drop(\"_merge\", axis=1)\n",
    "# print(F\"The amount of rows dropped for train/test split: {dropped_rows.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41d0de36-2131-469a-9ac3-3ffab26de794",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['spn', 'fmi', 'EquipmentID'] \n",
    "bool_features = ['CruiseControlActive', 'ParkingBrake', 'IgnStatus', 'active']\n",
    "numeric_features = [x for x in X_train.columns if x not in categorical_features + bool_features] \n",
    "#pca = PCA(n_components=1, svd_solver=\"arpack\")\n",
    "\n",
    "numeric_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('scale', StandardScaler()),\n",
    "        ('numeric_impute', SimpleImputer(strategy='most_frequent'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True)),\n",
    "        ('categorical_impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ]\n",
    ")\n",
    "\n",
    "bool_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('bool_impute', SimpleImputer(strategy='most_frequent'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_pipe, numeric_features),\n",
    "        ('categorical', categorical_pipe, categorical_features),\n",
    "        ('bool', bool_pipe, bool_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('transformer', ct),\n",
    "        #('pca', pca)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "X_train_transformed = pipe.transform(X_train)\n",
    "X_test_transformed = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f7531-0eb7-4f25-bf29-15d9b4847394",
   "metadata": {},
   "source": [
    "### Creating Pickle File for Storing Pipe Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b7f9aaa-770d-403c-a206-a68742505997",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pipe_transformed.pkl'\n",
    "\n",
    "pickle_list = [pipe, X_train_transformed, X_test_transformed]\n",
    "\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(pickle_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "371cd373-fe65-463a-a912-6850d62496c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'rb') as file:\n",
    "    pipe, X_train_transformed, X_test_transformed = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6613e-1a59-4afe-8b5c-6e2179fbff57",
   "metadata": {},
   "source": [
    "### Defining Model Evaluation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d0ceb-e081-4476-8cac-fd12e7c193df",
   "metadata": {},
   "source": [
    "### Smoting To Solve Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16bc07f5-207c-4ed2-a507-d67964ead2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_trained_smoted, y_trained_smoted = smote.fit_resample(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f937f4-231c-4b21-a06b-123dc44a0943",
   "metadata": {},
   "source": [
    "### Defining The Function to Evaluate Performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7ac25-d652-4875-b5d0-b8dff145b75a",
   "metadata": {},
   "source": [
    "### LGBMClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc791b1e-49ac-4e62-b807-1bda7d44ac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 154277, number of negative: 154277\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59558\n",
      "[LightGBM] [Info] Number of data points in the train set: 308554, number of used features: 556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[[19811   145]\n",
      " [ 1022    18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.99      0.97     19956\n",
      "        True       0.11      0.02      0.03      1040\n",
      "\n",
      "    accuracy                           0.94     20996\n",
      "   macro avg       0.53      0.51      0.50     20996\n",
      "weighted avg       0.91      0.94      0.92     20996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LGBMClassiferModel = LGBMClassifier()\n",
    "LGBMClassiferModel = LGBMClassiferModel.fit(X_trained_smoted, y_trained_smoted)\n",
    "LGBMClassifer_y_pred = LGBMClassiferModel.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, LGBMClassifer_y_pred))\n",
    "print(classification_report(y_test, LGBMClassifer_y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd476e-ca7f-488c-b459-835cb53f6a7a",
   "metadata": {},
   "source": [
    "#### LGBM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc4f8dba-7d7c-45da-8c5c-88bc9b383467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=10. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=10. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Number of positive: 154277, number of negative: 154277\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59558\n",
      "[LightGBM] [Info] Number of data points in the train set: 308554, number of used features: 556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters: OrderedDict({'alpha': 1, 'colsample_bytree': 0.6, 'lambda': 10, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 500, 'subsample': 0.6})\n",
      "Best score: 0.8999030332965509\n"
     ]
    }
   ],
   "source": [
    "param_grid = param_ranges = {\n",
    "    \"max_depth\": [3, 6, 9],  # Controls tree complexity\n",
    "    \"learning_rate\": [0.01, 0.1, 0.3],  # Step size for weight updates\n",
    "    \"subsample\": [0.6, 0.8, 1.0],  # Fraction of samples used per boosting iteration\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],  # Fraction of features used per tree\n",
    "    \"lambda\": [0.1, 1, 10],  # L2 regularization\n",
    "    \"alpha\": [0.1, 0.5, 1],  # L1 regularization\n",
    "    \"n_estimators\": [100, 500, 1000]  # Number of boosting rounds\n",
    "}\n",
    "bayes_search = BayesSearchCV(estimator=LGBMClassiferModel, search_spaces=param_grid, n_iter=25, cv=3, n_jobs=-1, verbose=2, scoring=\"f1\")\n",
    "bayes_search.fit(X_trained_smoted, y_trained_smoted)\n",
    "\n",
    "best_params = bayes_search.best_params_\n",
    "print(f\"Best parameters: {bayes_search.best_params_}\")\n",
    "print(f\"Best score: {bayes_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25818202-7cbd-40f9-8b11-323e675bd466",
   "metadata": {},
   "source": [
    "#### LGBM Model Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d84760d-f5a6-4171-8256-f1c7e423b458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=10. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=10. Current value: lambda_l2=10\n",
      "[LightGBM] [Info] Number of positive: 154277, number of negative: 154277\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59558\n",
      "[LightGBM] [Info] Number of data points in the train set: 308554, number of used features: 556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] lambda_l2 is set with reg_lambda=0.0, will be overridden by lambda=10. Current value: lambda_l2=10\n",
      "[[19941    15]\n",
      " [ 1037     3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      1.00      0.97     19956\n",
      "        True       0.17      0.00      0.01      1040\n",
      "\n",
      "    accuracy                           0.95     20996\n",
      "   macro avg       0.56      0.50      0.49     20996\n",
      "weighted avg       0.91      0.95      0.93     20996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LGBMClassifierTuned = LGBMClassifier(**best_params)\n",
    "LGBMClassifierTuned.fit(X_trained_smoted, y_trained_smoted)\n",
    "LGBMClassiferTuned_y_pred = LGBMClassifierTuned.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, LGBMClassiferTuned_y_pred))\n",
    "print(classification_report(y_test, LGBMClassiferTuned_y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63c51fa0-772a-4745-a312-6cd81d46f9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMClassiferTuned_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848abbe-38f8-4da0-af09-2caa61f12e97",
   "metadata": {},
   "source": [
    "### XGBClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcfebf80-9f7d-4dac-a853-5c8fccf71a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19833   123]\n",
      " [ 1035     5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.99      0.97     19956\n",
      "        True       0.04      0.00      0.01      1040\n",
      "\n",
      "    accuracy                           0.94     20996\n",
      "   macro avg       0.49      0.50      0.49     20996\n",
      "weighted avg       0.91      0.94      0.92     20996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGBClassiferModel = XGBClassifier()\n",
    "XGBClassiferModel.fit(X_trained_smoted, y_trained_smoted)\n",
    "XGBClassifer_y_pred = XGBClassiferModel.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, XGBClassifer_y_pred))\n",
    "print(classification_report(y_test, XGBClassifer_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76160420-cf7b-46c5-a551-f68c489b2b3b",
   "metadata": {},
   "source": [
    "#### XGB Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f043b67-8ece-4abd-84f9-7364b2987e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters: OrderedDict({'alpha': 1, 'colsample_bytree': 0.8, 'lambda': 10, 'learning_rate': 0.3, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 1000, 'subsample': 0.6})\n",
      "Best score: 0.9027872225809895\n"
     ]
    }
   ],
   "source": [
    "param_grid = param_ranges = {\n",
    "    \"max_depth\": [3, 6, 9],  # Controls tree complexity\n",
    "    \"learning_rate\": [0.01, 0.1, 0.3],  # Step size for weight updates\n",
    "    \"subsample\": [0.6, 0.8, 1.0],  # Fraction of samples used per boosting iteration\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],  # Fraction of features used per tree\n",
    "    \"min_child_weight\": [1, 3, 5],  # Minimum sum of instance weight in child node\n",
    "    \"lambda\": [0.1, 1, 10],  # L2 regularization\n",
    "    \"alpha\": [0, 0.5, 1],  # L1 regularization\n",
    "    \"n_estimators\": [100, 500, 1000]  # Number of boosting rounds\n",
    "}\n",
    "bayes_search = BayesSearchCV(estimator=XGBClassiferModel, search_spaces=param_grid, n_iter=25, cv=3, n_jobs=-1, verbose=2, scoring=\"f1\")\n",
    "bayes_search.fit(X_trained_smoted, y_trained_smoted)\n",
    "\n",
    "best_params = bayes_search.best_params_\n",
    "print(f\"Best parameters: {bayes_search.best_params_}\")\n",
    "print(f\"Best score: {bayes_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d8c3e-74ff-4fc7-a9d3-26b7b559f1f0",
   "metadata": {},
   "source": [
    "#### XGB Model Tuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b6b64df-05cb-48ee-854d-0442439af186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19936    20]\n",
      " [ 1036     4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      1.00      0.97     19956\n",
      "        True       0.17      0.00      0.01      1040\n",
      "\n",
      "    accuracy                           0.95     20996\n",
      "   macro avg       0.56      0.50      0.49     20996\n",
      "weighted avg       0.91      0.95      0.93     20996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGBClassifierTuned = XGBClassifier(**best_params)\n",
    "XGBClassifierTuned.fit(X_trained_smoted, y_trained_smoted)\n",
    "XGBClassifierTuned_y_pred = XGBClassifierTuned.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, XGBClassifierTuned_y_pred))\n",
    "print(classification_report(y_test, XGBClassifierTuned_y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f910b-5da9-406d-b03d-f98ed668ae47",
   "metadata": {},
   "source": [
    "### Decision Tree Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75e1bc30-6444-4e11-804a-26cfdb987a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19204   752]\n",
      " [  985    55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.96      0.96     19956\n",
      "        True       0.07      0.05      0.06      1040\n",
      "\n",
      "    accuracy                           0.92     20996\n",
      "   macro avg       0.51      0.51      0.51     20996\n",
      "weighted avg       0.91      0.92      0.91     20996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTreeClassifierModel = DecisionTreeClassifier()\n",
    "DecisionTreeClassifierModel.fit(X_trained_smoted, y_trained_smoted)\n",
    "DecisionTreeClassifierModel_y_pred = DecisionTreeClassifierModel.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, DecisionTreeClassifierModel_y_pred))\n",
    "print(classification_report(y_test, DecisionTreeClassifierModel_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfb474-462b-4c47-8150-787be9888a3a",
   "metadata": {},
   "source": [
    "#### Decision Tree Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07eee6a2-f5fc-4aee-84e4-99050ed76646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters: OrderedDict({'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'max_leaf_nodes': 50, 'min_samples_leaf': 5, 'min_samples_split': 10})\n",
      "Best score: 0.6748085381823862\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 6, 9],  \n",
    "    \"min_samples_split\": [2, 5, 10],  \n",
    "    \"min_samples_leaf\": [1, 3, 5],  \n",
    "    \"max_features\": [\"sqrt\", \"log2\"],  # Removed \"auto\"\n",
    "    \"criterion\": [\"gini\", \"entropy\"],  \n",
    "    \"max_leaf_nodes\": [None, 10, 50]\n",
    "}\n",
    "bayes_search = BayesSearchCV(estimator=DecisionTreeClassifierModel, search_spaces=param_grid, n_iter=25, cv=3, n_jobs=-1, verbose=2, scoring=\"f1\")\n",
    "bayes_search.fit(X_trained_smoted, y_trained_smoted)\n",
    "\n",
    "best_params = bayes_search.best_params_\n",
    "print(f\"Best parameters: {bayes_search.best_params_}\")\n",
    "print(f\"Best score: {bayes_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4502e8-972d-4807-bab9-0c5d1696c26b",
   "metadata": {},
   "source": [
    "#### DecisionTree Model Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a6bb86b-88c7-4063-b307-cbf46bb4e482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19053   903]\n",
      " [ 1009    31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.95      0.95     19956\n",
      "        True       0.03      0.03      0.03      1040\n",
      "\n",
      "    accuracy                           0.91     20996\n",
      "   macro avg       0.49      0.49      0.49     20996\n",
      "weighted avg       0.90      0.91      0.91     20996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DecisionTreeClassifierTuned = DecisionTreeClassifier(**best_params)\n",
    "DecisionTreeClassifierTuned.fit(X_trained_smoted, y_trained_smoted)\n",
    "DecisionTreeClassifierTuned_y_pred = DecisionTreeClassifierTuned.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, DecisionTreeClassifierTuned_y_pred))\n",
    "print(classification_report(y_test, DecisionTreeClassifierTuned_y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282a646-c908-4db0-950f-3a95bbfbfc97",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bfb4e55-c081-4a0a-bd42-1880d5185b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11588  8368]\n",
      " [  642   398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.58      0.72     19956\n",
      "        True       0.05      0.38      0.08      1040\n",
      "\n",
      "    accuracy                           0.57     20996\n",
      "   macro avg       0.50      0.48      0.40     20996\n",
      "weighted avg       0.90      0.57      0.69     20996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogisticRegressionModel = LogisticRegression(max_iter=500)\n",
    "LogisticRegressionModel.fit(X_trained_smoted, y_trained_smoted)\n",
    "LogisticRegressionModel_y_pred = LogisticRegressionModel.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, LogisticRegressionModel_y_pred))\n",
    "print(classification_report(y_test, LogisticRegressionModel_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49eb2fa-c2ec-4431-9e44-b33f1e4bba30",
   "metadata": {},
   "source": [
    "#### Logisitic Regression Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2ec2c35-af19-4e46-a636-469f7c6c73fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100, 200, 'l1', 'liblinear'] before, using random point [100, 500, 'l2', 'liblinear']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\anaconda3\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [100, 200, 'l1', 'liblinear'] before, using random point [0.01, 1000, 'l2', 'liblinear']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters: OrderedDict({'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'})\n",
      "Best score: 0.6612965229582387\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],  # Type of regularization\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength (inverse of λ)\n",
    "    \"solver\": [\"liblinear\"],  # Optimizer for l1/l2 penalties\n",
    "    \"max_iter\": [100, 200, 500, 1000]  # Iterations for convergence\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(estimator=LogisticRegressionModel, search_spaces=param_grid, n_iter=25, cv=3, n_jobs=-1, verbose=2, scoring=\"f1\")\n",
    "bayes_search.fit(X_trained_smoted, y_trained_smoted)\n",
    "\n",
    "best_params = bayes_search.best_params_\n",
    "print(f\"Best parameters: {bayes_search.best_params_}\")\n",
    "print(f\"Best score: {bayes_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48c4c2fa-f657-4d3c-a0d3-ba6a4348be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11914  8042]\n",
      " [  695   345]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.60      0.73     19956\n",
      "        True       0.04      0.33      0.07      1040\n",
      "\n",
      "    accuracy                           0.58     20996\n",
      "   macro avg       0.49      0.46      0.40     20996\n",
      "weighted avg       0.90      0.58      0.70     20996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogisticRegressionModelTuned = LogisticRegression(**best_params)\n",
    "LogisticRegressionModelTuned.fit(X_trained_smoted, y_trained_smoted)\n",
    "LogisticRegressionModelTuned_y_pred = LogisticRegressionModelTuned.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, LogisticRegressionModelTuned_y_pred))\n",
    "print(classification_report(y_test, LogisticRegressionModelTuned_y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda38bb-4c2e-4e54-98bd-d6e7dae2091e",
   "metadata": {},
   "source": [
    "### KNN Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "332691d7-802d-4f78-84f9-b1fa03802b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "KNeighborsClassifierModel = KNeighborsClassifier()\n",
    "KNeighborsClassifierModel.fit(X_trained_smoted, y_trained_smoted)\n",
    "KNeighborsClassifierModel_y_pred = KNeighborsClassifierModel.predict(X_test_transformed)\n",
    "print(confusion_matrix(y_test, KNeighborsClassifierModel_y_pred))\n",
    "print(classification_report(y_test, KNeighborsClassifierModel_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14345d44-3940-4805-984f-27978acab2ff",
   "metadata": {},
   "source": [
    "##### I've aborted the Hyperparameter tuning for KNN because it doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33f04c-50fe-4431-8d20-f816dc100a7a",
   "metadata": {},
   "source": [
    "#### KNN Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94e425e5-6aa0-4dbb-9aac-c86170793a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     \"n_neighbors\": [3, 5, 7, 9, 11],  # Number of nearest neighbors\n",
    "#     \"weights\": [\"uniform\", \"distance\"],  # How neighbors influence prediction\n",
    "#     \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # Distance calculation method\n",
    "#     \"p\": [1, 2],  # Minkowski power parameter (1 = Manhattan, 2 = Euclidean)\n",
    "# }\n",
    "\n",
    "# bayes_search = BayesSearchCV(estimator=KNeighborsClassifierModel, search_spaces=param_grid, n_iter=25, cv=3, n_jobs=-1, verbose=2, scoring=\"f1\")\n",
    "# bayes_search.fit(X_trained_smoted, y_trained_smoted)\n",
    "\n",
    "# best_params = bayes_search.best_params_\n",
    "# print(f\"Best parameters: {bayes_search.best_params_}\")\n",
    "# print(f\"Best score: {bayes_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04b0b8-8461-43da-b032-835ae0a1833c",
   "metadata": {},
   "source": [
    "#### KNN Model tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4156413a-892e-4cfd-87f1-763f71b0dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifierModelTuned = LogisticRegression(**best_params)\n",
    "# KNeighborsClassifierModelTuned.fit(X_trained_smoted, y_trained_smoted)\n",
    "# KNeighborsClassifierModelTuned_y_pred = KNeighborsClassifierModelTuned.predict(X_test_transformed)\n",
    "# print(confusion_matrix(y_test, KNeighborsClassifierModelTuned_y_pred))\n",
    "# print(classification_report(y_test, KNeighborsClassifierModelTuned_y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248c2e1-a496-43e4-ab72-3d0f534057fe",
   "metadata": {},
   "source": [
    "### Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "5e49199c-2a4c-477f-9f59-2609814766d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['true negative', 'false positive', 'false negative', 'true positive'], dtype='object', name='combined')\n",
      "combined\n",
      "true positive      5\n",
      "false positive    18\n",
      "false negative    37\n",
      "true negative     21\n",
      "dtype: int64\n",
      "11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_37412\\1272323862.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['combined'] = pred_df['target'].astype(str) + '_' + pred_df['predictions'].astype(str)\n",
      "C:\\Users\\billy\\AppData\\Local\\Temp\\ipykernel_37412\\1272323862.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['EventTimeStamp'] = pd.to_datetime(pred_df['EventTimeStamp'])\n"
     ]
    }
   ],
   "source": [
    "df_test['predictions'] = XGBClassifer_y_pred\n",
    "df_test['predictions'] = df_test['predictions'].replace({0: 'False', 1: 'True'})\n",
    "pred_df = df_test[['EventTimeStamp', 'EquipmentID', 'spn', 'target', 'predictions']]\n",
    "pred_df['combined'] = pred_df['target'].astype(str) + '_' + pred_df['predictions'].astype(str)\n",
    "pred_df['EventTimeStamp'] = pd.to_datetime(pred_df['EventTimeStamp'])\n",
    "pred_df = pred_df.sort_values(by=['EquipmentID', 'EventTimeStamp'])\n",
    "pred_df['time_diff'] = pred_df.groupby('EquipmentID', observed=True)['EventTimeStamp'].diff().dt.total_seconds() / 3600\n",
    "pred_df['valid_group'] = (pred_df['time_diff'].isna()) | (pred_df['time_diff'] <= 2)\n",
    "pred_df['temp_group'] = (~pred_df['valid_group']).cumsum()\n",
    "result = pred_df.groupby(['EquipmentID', 'temp_group'], observed=True)['combined'].value_counts().reset_index()\n",
    "result = pred_df.groupby(['EquipmentID', 'temp_group'], observed=True)['combined'].value_counts().unstack(fill_value=0).drop_duplicates()\n",
    "result\n",
    "result = result.rename(columns = {'False_False': 'true negative', 'False_True': 'false positive', 'True_False': 'false negative', 'True_True': 'true positive'})\n",
    "print(result.columns)\n",
    "\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    if row['true positive'] >= 1:\n",
    "        result.loc[index, 'true positive'] = 1\n",
    "        result.loc[index, ~result.columns.isin(['true positive'])] = 0\n",
    "    elif row['true positive'] == 0 and row['false positive'] >= 1:\n",
    "        result.loc[index, 'false positive'] = 1\n",
    "        result.loc[index, ~result.columns.isin(['false positive', 'true positive'])] = 0\n",
    "    elif row['true positive'] == 0 and row['false positive'] == 0 and row['false negative'] >= 1:\n",
    "        result.loc[index, 'false negative'] = 1\n",
    "        result.loc[index, ~result.columns.isin(['false negative', 'false positive', 'true positive'])] = 0\n",
    "    else:\n",
    "        result.loc[index, 'true negative'] = 1\n",
    "    counts = (result.iloc[:,0].sum() * 0) - (result.iloc[:,1].sum() * 500) + (result.iloc[:,3].sum() * 4000)\n",
    "print(result[['true positive', 'false positive', 'false negative', 'true negative']].sum())\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "798c20ca-843e-49ba-808b-ee96b0e9b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_pred(df, event, equipment, target, pred):\n",
    "    df = df[[event, equipment, target]].copy()\n",
    "    df['predict'] = pred\n",
    "    df['predict'] = df['predict'].replace({0: 'False', 1: 'True'})\n",
    "    df['combined'] = df[target].astype(str) + '_' + df['predict'].astype(str)\n",
    "    df[event] = pd.to_datetime(df[event])\n",
    "    df = df.sort_values(by=[equipment, event])\n",
    "    df['time_diff'] = df.groupby(equipment, observed=True)[event].diff().dt.total_seconds() / 3600\n",
    "    df['valid_group'] = (df['time_diff'].isna()) | (df['time_diff'] <= 2)\n",
    "    df['temp_group'] = (~df['valid_group']).cumsum()\n",
    "    result = df.groupby([equipment, 'temp_group'], observed=True)['combined'].value_counts().reset_index()\n",
    "    result = df.groupby([equipment, 'temp_group'], observed=True)['combined'].value_counts().unstack(fill_value=0).drop_duplicates()\n",
    "    result = result.rename(columns = {'False_False': 'true negative', 'False_True': 'false positive', 'True_False': 'false negative', 'True_True': 'true positive'})\n",
    "    \n",
    "    for index, row in result.iterrows():\n",
    "        if row['true positive'] >= 1:\n",
    "            result.loc[index, 'true positive'] = 1\n",
    "            result.loc[index, ~result.columns.isin(['true positive'])] = 0\n",
    "        elif row['true positive'] == 0 and row['false positive'] >= 1:\n",
    "            result.loc[index, 'false positive'] = 1\n",
    "            result.loc[index, ~result.columns.isin(['false positive', 'true positive'])] = 0\n",
    "        elif row['true positive'] == 0 and row['false positive'] == 0 and row['false negative'] >= 1:\n",
    "            result.loc[index, 'false negative'] = 1\n",
    "            result.loc[index, ~result.columns.isin(['false negative', 'false positive', 'true positive'])] = 0\n",
    "        else:\n",
    "            result.loc[index, 'true negative'] = 1\n",
    "    counts = (result.iloc[:,0].sum() * 0) - (result.iloc[:,1].sum() * 500) + (result.iloc[:,3].sum() * 4000)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "de991dfc-6d61-475a-b88f-f67dd150cd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LGBM Model saved: 13500\n",
      "The LGBM Model tuned saved: 4500\n",
      "The XGBoost Model  saved: 11000\n",
      "The XGBoost Model tuned saved: 5000\n",
      "The Decision Tree Model saved: 33000\n",
      "The Decision Tree Model Tuned saved: 11000\n",
      "The Logistic Regression Model saved: 121000\n",
      "The Logistic Regression Model Tuned saved: 98500\n",
      "The KNN Model saved: 121000\n"
     ]
    }
   ],
   "source": [
    "print(F\"The LGBM Model saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', LGBMClassifer_y_pred)}\")\n",
    "print(F\"The LGBM Model tuned saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', LGBMClassiferTuned_y_pred)}\")\n",
    "print(F\"The XGBoost Model  saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', XGBClassifer_y_pred)}\")\n",
    "print(F\"The XGBoost Model tuned saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', XGBClassifierTuned_y_pred)}\")\n",
    "print(F\"The Decision Tree Model saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', DecisionTreeClassifierModel_y_pred)}\")\n",
    "print(F\"The Decision Tree Model Tuned saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', DecisionTreeClassifierTuned_y_pred)}\")\n",
    "print(F\"The Logistic Regression Model saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', LogisticRegressionModel_y_pred)}\")\n",
    "print(F\"The Logistic Regression Model Tuned saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', LogisticRegressionModelTuned_y_pred)}\")\n",
    "print(F\"The KNN Model saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', KNeighborsClassifierModel_y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "59b0621e-bd32-4e58-868f-0644db77446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LGBM Model tuned saved: 5000\n"
     ]
    }
   ],
   "source": [
    "print(F\"The LGBM Model tuned saved: {target_pred(df_test, 'EventTimeStamp', 'EquipmentID', 'target', XGBClassifierTuned_y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5a78e-bb64-4ff2-af8c-2b242b87536d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
